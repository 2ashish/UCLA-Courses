import numpy as np

class ValueIteration(object):
    def __init__(self, transitionTable, rewardTable, valueTable, convergenceTolerance, discountingFactor = 1):
        self.transitionTable = transitionTable
        self.rewardTable  = rewardTable
        self.valueTable = valueTable
        self.convergenceTolerance = convergenceTolerance
        self.gamma = discountingFactor

    def __call__(self):
        theta = self.convergenceTolerance*100
        while(theta > self.convergenceTolerance):
            theta = 0
            for state, actionDict in self.transitionTable.items():

                valueOfStateAtTimeT = self.valueTable[state]
                self.valueTable[state] = max([self.getQValue(state, action) for action in actionDict.keys()])
                theta = max(theta, abs(valueOfStateAtTimeT-self.valueTable[state]))

        policyTable = {state:self.getStatePolicy(state) for state in self.transitionTable.keys()}
        return([self.valueTable, policyTable])
    
    def getStatePolicy(self, state):
        roundingThreshold = 5

        maxQValue = max([round(self.getQValue(state, action),roundingThreshold) for action in self.transitionTable[state].keys()])
        optimalActionSet = [action for action in self.transitionTable[state].keys() \
                            if round(self.getQValue(state, action),roundingThreshold) == maxQValue]
        statePolicy = {action: 1/(len(optimalActionSet)) for action in optimalActionSet}
        return(statePolicy)
        
    def getQValue(self, state, action):
        nextStatesQ = [prob*(self.rewardTable[state][action][nextState] \
                             + self.gamma*self.valueTable[nextState]) \
                      for nextState, prob in self.transitionTable[state][action].items()]
        qValue = sum(nextStatesQ)
        return(qValue)


def main():
    #Example 1: Deterministic Transition
    #When transitions are deterministic, the optimal policy is always to take the action or actions that move you closer to the goal state while avoiding the trap.
    transitionTableDet = {(0, 0): {(1, 0): {(1, 0): 1},(0, 1): {(0, 1): 1},(-1, 0): {(0, 0): 1},(0, -1): {(0, 0): 1}},(0, 1): {(1, 0): {(1, 1): 1},(0, 1): {(0, 2): 1},(-1, 0): {(0, 1): 1},(0, -1): {(0, 0): 1}},(0, 2): {(1, 0): {(1, 2): 1},(0, 1): {(0, 3): 1},(-1, 0): {(0, 2): 1},(0, -1): {(0, 1): 1}},(0, 3): {(1, 0): {(1, 3): 1},(0, 1): {(0, 4): 1},(-1, 0): {(0, 3): 1},(0, -1): {(0, 2): 1}},(0, 4): {(1, 0): {(1, 4): 1},(0, 1): {(0, 4): 1},(-1, 0): {(0, 4): 1},(0, -1): {(0, 3): 1}},(1, 0): {(1, 0): {(2, 0): 1},(0, 1): {(1, 1): 1},(-1, 0): {(0, 0): 1},(0, -1): {(1, 0): 1}},(1, 1): {(1, 0): {(2, 1): 1},(0, 1): {(1, 2): 1},(-1, 0): {(0, 1): 1},(0, -1): {(1, 0): 1}},(1, 2): {(1, 0): {(2, 2): 1},(0, 1): {(1, 3): 1},(-1, 0): {(0, 2): 1},(0, -1): {(1, 1): 1}},(1, 3): {(1, 0): {(2, 3): 1},(0, 1): {(1, 4): 1},(-1, 0): {(0, 3): 1},(0, -1): {(1, 2): 1}},(1, 4): {(1, 0): {(2, 4): 1},(0, 1): {(1, 4): 1},(-1, 0): {(0, 4): 1},(0, -1): {(1, 3): 1}},(2, 0): {(1, 0): {(2, 0): 1},(0, 1): {(2, 1): 1},(-1, 0): {(1, 0): 1},(0, -1): {(2, 0): 1}},(2, 1): {(1, 0): {(2, 1): 1},(0, 1): {(2, 2): 1},(-1, 0): {(1, 1): 1},(0, -1): {(2, 0): 1}},(2, 2): {(1, 0): {(2, 2): 1},(0, 1): {(2, 3): 1},(-1, 0): {(1, 2): 1},(0, -1): {(2, 1): 1}},(2, 3): {(1, 0): {(2, 3): 1},(0, 1): {(2, 4): 1},(-1, 0): {(1, 3): 1},(0, -1): {(2, 2): 1}},(2, 4): {(1, 0): {(2, 4): 1},(0, 1): {(2, 4): 1},(-1, 0): {(1, 4): 1},(0, -1): {(2, 3): 1}}}
    rewardTableDet = {(0, 0): {(1, 0): {(1, 0): -1},(0, 1): {(0, 1): -1},(-1, 0): {(0, 0): -1},(0, -1): {(0, 0): -1}},(0, 1): {(1, 0): {(1, 1): -1},(0, 1): {(0, 2): -1},(-1, 0): {(0, 1): -1},(0, -1): {(0, 0): -1}},(0, 2): {(1, 0): {(1, 2): -1},(0, 1): {(0, 3): -1},(-1, 0): {(0, 2): -1},(0, -1): {(0, 1): -1}},(0, 3): {(1, 0): {(1, 3): -1},(0, 1): {(0, 4): -1},(-1, 0): {(0, 3): -1},(0, -1): {(0, 2): -1}},(0, 4): {(1, 0): {(1, 4): -1},(0, 1): {(0, 4): -1},(-1, 0): {(0, 4): -1},(0, -1): {(0, 3): -1}},(1, 0): {(1, 0): {(2, 0): -1},(0, 1): {(1, 1): -1},(-1, 0): {(0, 0): -1},(0, -1): {(1, 0): -1}},(1, 1): {(1, 0): {(2, 1): 10},(0, 1): {(1, 2): 10},(-1, 0): {(0, 1): 10},(0, -1): {(1, 0): 10}},(1, 2): {(1, 0): {(2, 2): -100},(0, 1): {(1, 3): -100},(-1, 0): {(0, 2): -100},(0, -1): {(1, 1): -100}},(1, 3): {(1, 0): {(2, 3): -1},(0, 1): {(1, 4): -1},(-1, 0): {(0, 3): -1},(0, -1): {(1, 2): -1}},(1, 4): {(1, 0): {(2, 4): -1},(0, 1): {(1, 4): -1},(-1, 0): {(0, 4): -1},(0, -1): {(1, 3): -1}},(2, 0): {(1, 0): {(2, 0): -1},(0, 1): {(2, 1): -1},(-1, 0): {(1, 0): -1},(0, -1): {(2, 0): -1}},(2, 1): {(1, 0): {(2, 1): -1},(0, 1): {(2, 2): -1},(-1, 0): {(1, 1): -1},(0, -1): {(2, 0): -1}},(2, 2): {(1, 0): {(2, 2): -1},(0, 1): {(2, 3): -1},(-1, 0): {(1, 2): -1},(0, -1): {(2, 1): -1}},(2, 3): {(1, 0): {(2, 3): -1},(0, 1): {(2, 4): -1},(-1, 0): {(1, 3): -1},(0, -1): {(2, 2): -1}},(2, 4): {(1, 0): {(2, 4): -1},(0, 1): {(2, 4): -1},(-1, 0): {(1, 4): -1},(0, -1): {(2, 3): -1}}}
    valueTableDet = {(0, 0): 0,(0, 1): 0,(0, 2): 0,(0, 3): 0,(0, 4): 0,(1, 0): 0,(1, 1): 0,(1, 2): 0,(1, 3): 0,(1, 4): 0,(2, 0): 0,(2, 1): 0,(2, 2): 0,(2, 3): 0,(2, 4): 0}
    convergenceTolerance = 10e-7
    gamma = .9
    performValueIteration = ValueIteration(transitionTableDet, rewardTableDet, valueTableDet, convergenceTolerance, gamma)
    optimalValuesDeterminsitic, policyTableDet = performValueIteration()
    print(optimalValuesDeterminsitic)
    print(policyTableDet)
    
    #Example 2: Probabilistic Transition
    transitionTable = {(0, 0): {(1, 0): {(1, 0): 0.7, (0, 1): 0.2, (0, 0): 0.1},(0, 1): {(0, 1): 0.7999999999999999, (1, 0): 0.2},(-1, 0): {(0, 0): 0.7, (1, 0): 0.2, (0, 1): 0.1},(0, -1): {(0, 0): 0.7, (1, 0): 0.1, (0, 1): 0.2}},(0, 1): {(1, 0): {(1, 1): 0.7999999999999999, (0, 1): 0.1, (0, 2): 0.1},(0, 1): {(0, 2): 0.7999999999999999, (0, 0): 0.2},(-1, 0): {(0, 1): 0.8999999999999999, (0, 0): 0.1},(0, -1): {(0, 0): 0.7999999999999999, (0, 2): 0.1, (0, 1): 0.1}},(0, 2): {(1, 0): {(1, 2): 0.7999999999999999, (0, 1): 0.2},(0, 1): {(0, 3): 0.7999999999999999, (0, 1): 0.1, (1, 2): 0.1},(-1, 0): {(0, 2): 0.7, (0, 1): 0.1, (1, 2): 0.1, (0, 3): 0.1},(0, -1): {(0, 1): 0.8999999999999999, (0, 3): 0.1}},(0, 3): {(1, 0): {(1, 3): 0.8999999999999999, (0, 2): 0.1},(0, 1): {(0, 3): 0.9999999999999999},(-1, 0): {(0, 3): 0.7999999999999999, (0, 2): 0.1, (1, 3): 0.1},(0, -1): {(0, 2): 0.7999999999999999, (0, 3): 0.2}},(1, 0): {(1, 0): {(2, 0): 0.8999999999999999, (1, 1): 0.1},(0, 1): {(1, 1): 0.8999999999999999, (1, 0): 0.1},(-1, 0): {(0, 0): 0.7, (1, 1): 0.2, (2, 0): 0.1},(0, -1): {(1, 0): 0.7999999999999999, (0, 0): 0.2}},(1, 1): {(1, 0): {(2, 1): 0.7999999999999999, (1, 0): 0.1, (0, 1): 0.1},(0, 1): {(1, 2): 0.7, (2, 1): 0.30000000000000004},(-1, 0): {(0, 1): 0.7, (2, 1): 0.1, (1, 0): 0.2},(0, -1): {(1, 0): 0.7999999999999999, (0, 1): 0.1, (2, 1): 0.1}},(1, 2): {(1, 0): {(2, 2): 0.7999999999999999, (1, 3): 0.1, (1, 1): 0.1},(0, 1): {(1, 3): 0.8999999999999999, (2, 2): 0.1},(-1, 0): {(0, 2): 0.8999999999999999, (1, 1): 0.1},(0, -1): {(1, 1): 0.7999999999999999, (2, 2): 0.1, (0, 2): 0.1}},(1, 3): {(1, 0): {(2, 3): 0.7999999999999999, (1, 3): 0.2},(0, 1): {(1, 3): 0.7999999999999999, (2, 3): 0.1, (0, 3): 0.1},(-1, 0): {(0, 3): 0.7, (2, 3): 0.1, (1, 2): 0.2},(0, -1): {(1, 2): 0.7999999999999999, (0, 3): 0.2}},(2, 0): {(1, 0): {(3, 0): 0.8999999999999999, (2, 0): 0.1},(0, 1): {(2, 1): 0.7999999999999999, (3, 0): 0.1, (1, 0): 0.1},(-1, 0): {(1, 0): 0.7, (2, 0): 0.2, (2, 1): 0.1},(0, -1): {(2, 0): 0.7, (2, 1): 0.2, (1, 0): 0.1}},(2, 1): {(1, 0): {(3, 1): 0.7999999999999999, (1, 1): 0.2},(0, 1): {(2, 2): 0.7, (1, 1): 0.1, (3, 1): 0.2},(-1, 0): {(1, 1): 0.7, (2, 0): 0.1, (2, 2): 0.1, (3, 1): 0.1},(0, -1): {(2, 0): 0.7, (1, 1): 0.2, (3, 1): 0.1}},(2, 2): {(1, 0): {(3, 2): 0.7, (1, 2): 0.1, (2, 1): 0.2},(0, 1): {(2, 3): 0.7999999999999999, (2, 1): 0.2},(-1, 0): {(1, 2): 0.7999999999999999, (2, 1): 0.1, (3, 2): 0.1},(0, -1): {(2, 1): 0.7999999999999999, (1, 2): 0.1, (3, 2): 0.1}},(2, 3): {(1, 0): {(3, 3): 0.7, (2, 3): 0.2, (2, 2): 0.1},(0, 1): {(2, 3): 0.7999999999999999, (2, 2): 0.1, (3, 3): 0.1},(-1, 0): {(1, 3): 0.8999999999999999, (2, 3): 0.1},(0, -1): {(2, 2): 0.7, (3, 3): 0.1, (1, 3): 0.1, (2, 3): 0.1}},(3, 0): {(1, 0): {(3, 0): 0.7, (3, 1): 0.1, (2, 0): 0.2},(0, 1): {(3, 1): 0.7999999999999999, (2, 0): 0.2},(-1, 0): {(2, 0): 0.7999999999999999, (3, 0): 0.2},(0, -1): {(3, 0): 0.7999999999999999, (2, 0): 0.1, (3, 1): 0.1}},(3, 1): {(1, 0): {(3, 1): 0.8999999999999999, (3, 2): 0.1},(0, 1): {(3, 2): 0.7, (2, 1): 0.2, (3, 0): 0.1},(-1, 0): {(2, 1): 0.7999999999999999, (3, 0): 0.1, (3, 1): 0.1},(0, -1): {(3, 0): 0.7999999999999999, (2, 1): 0.2}},(3, 2): {(1, 0): {(3, 2): 0.7999999999999999, (3, 1): 0.1, (2, 2): 0.1},(0, 1): {(3, 3): 0.7, (3, 2): 0.2, (2, 2): 0.1},(-1, 0): {(2, 2): 0.9999999999999999},(0, -1): {(3, 1): 0.7999999999999999, (3, 3): 0.1, (3, 2): 0.1}},(3, 3): {(1, 0): {(3, 3): 0.7999999999999999, (3, 2): 0.2},(0, 1): {(3, 3): 0.7999999999999999, (3, 2): 0.2},(-1, 0): {(2, 3): 0.7999999999999999, (3, 2): 0.1, (3, 3): 0.1},(0, -1): {(3, 2): 0.7999999999999999, (2, 3): 0.2}}}
    rewardTable = {(0, 0): {(1, 0): {(1, 0): -1, (0, 1): -1, (0, 0): -1},(0, 1): {(0, 1): -1, (1, 0): -1},(-1, 0): {(0, 0): -1, (1, 0): -1, (0, 1): -1},(0, -1): {(0, 0): -1, (1, 0): -1, (0, 1): -1}},(0, 1): {(1, 0): {(1, 1): -1, (0, 1): -1, (0, 2): -1},(0, 1): {(0, 2): -1, (0, 0): -1},(-1, 0): {(0, 1): -1, (0, 0): -1},(0, -1): {(0, 0): -1, (0, 2): -1, (0, 1): -1}},(0, 2): {(1, 0): {(1, 2): -1, (0, 1): -1},(0, 1): {(0, 3): -1, (0, 1): -1, (1, 2): -1},(-1, 0): {(0, 2): -1, (0, 1): -1, (1, 2): -1, (0, 3): -1},(0, -1): {(0, 1): -1, (0, 3): -1}},(0, 3): {(1, 0): {(1, 3): -1, (0, 2): -1},(0, 1): {(0, 3): -1},(-1, 0): {(0, 3): -1, (0, 2): -1, (1, 3): -1},(0, -1): {(0, 2): -1, (0, 3): -1}},(1, 0): {(1, 0): {(2, 0): -1, (1, 1): -1},(0, 1): {(1, 1): -1, (1, 0): -1},(-1, 0): {(0, 0): -1, (1, 1): -1, (2, 0): -1},(0, -1): {(1, 0): -1, (0, 0): -1}},(1, 1): {(1, 0): {(2, 1): -100, (1, 0): -100, (0, 1): -100},(0, 1): {(1, 2): -100, (2, 1): -100},(-1, 0): {(0, 1): -100, (2, 1): -100, (1, 0): -100},(0, -1): {(1, 0): -100, (0, 1): -100, (2, 1): -100}},(1, 2): {(1, 0): {(2, 2): -1, (1, 3): -1, (1, 1): -1},(0, 1): {(1, 3): -1, (2, 2): -1},(-1, 0): {(0, 2): -1, (1, 1): -1},(0, -1): {(1, 1): -1, (2, 2): -1, (0, 2): -1}},(1, 3): {(1, 0): {(2, 3): -1, (1, 3): -1},(0, 1): {(1, 3): -1, (2, 3): -1, (0, 3): -1},(-1, 0): {(0, 3): -1, (2, 3): -1, (1, 2): -1},(0, -1): {(1, 2): -1, (0, 3): -1}},(2, 0): {(1, 0): {(3, 0): -1, (2, 0): -1},(0, 1): {(2, 1): -1, (3, 0): -1, (1, 0): -1},(-1, 0): {(1, 0): -1, (2, 0): -1, (2, 1): -1},(0, -1): {(2, 0): -1, (2, 1): -1, (1, 0): -1}},(2, 1): {(1, 0): {(3, 1): -1, (1, 1): -1},(0, 1): {(2, 2): -1, (1, 1): -1, (3, 1): -1},(-1, 0): {(1, 1): -1, (2, 0): -1, (2, 2): -1, (3, 1): -1},(0, -1): {(2, 0): -1, (1, 1): -1, (3, 1): -1}},(2, 2): {(1, 0): {(3, 2): -1, (1, 2): -1, (2, 1): -1},(0, 1): {(2, 3): -1, (2, 1): -1},(-1, 0): {(1, 2): -1, (2, 1): -1, (3, 2): -1},(0, -1): {(2, 1): -1, (1, 2): -1, (3, 2): -1}},(2, 3): {(1, 0): {(3, 3): -1, (2, 3): -1, (2, 2): -1},(0, 1): {(2, 3): -1, (2, 2): -1, (3, 3): -1},(-1, 0): {(1, 3): -1, (2, 3): -1},(0, -1): {(2, 2): -1, (3, 3): -1, (1, 3): -1, (2, 3): -1}},(3, 0): {(1, 0): {(3, 0): -1, (3, 1): -1, (2, 0): -1},(0, 1): {(3, 1): -1, (2, 0): -1},(-1, 0): {(2, 0): -1, (3, 0): -1},(0, -1): {(3, 0): -1, (2, 0): -1, (3, 1): -1}},(3, 1): {(1, 0): {(3, 1): -1, (3, 2): 10},(0, 1): {(3, 2): 10, (2, 1): 10, (3, 0): 10},(-1, 0): {(2, 1): 10, (3, 0): 10, (3, 1): -1},(0, -1): {(3, 0): 10, (2, 1): 10}},(3, 2): {(1, 0): {(3, 2): -1, (3, 1): -1, (2, 2): -1},(0, 1): {(3, 3): -1, (3, 2): -1, (2, 2): -1},(-1, 0): {(2, 2): -1},(0, -1): {(3, 1): -1, (3, 3): -1, (3, 2): -1}},(3, 3): {(1, 0): {(3, 3): -1, (3, 2): -1},(0, 1): {(3, 3): -1, (3, 2): -1},(-1, 0): {(2, 3): -1, (3, 2): -1, (3, 3): -1},(0, -1): {(3, 2): -1, (2, 3): -1}}}
    valueTable = {(0, 0): 0,(0, 1): 0,(0, 2): 0,(0, 3): 0,(1, 0): 0,(1, 1): 0,(1, 2): 0,(1, 3): 0,(2, 0): 0,(2, 1): 0,(2, 2): 0,(2, 3): 0,(3, 0): 0,(3, 1): 0,(3, 2): 0,(3, 3): 0}
    convergenceTolerance = 10e-7
    gamma = .9
    performValueIteration = ValueIteration(transitionTable, rewardTable, valueTable, convergenceTolerance, gamma)
    optimalValuesDeterminsitic, policyTable = performValueIteration()
    print(optimalValuesDeterminsitic)
    print(policyTable)

    #Example 3: Testing Example
    #Checks whether code outputs values equivalent to a given optimal value / policy table
    convergence = .000001
    gamma = .9
    transition = {(0, 0): {(1, 0): {(1, 0): 0.7, (0, 1): 0.2, (0, 0): 0.1},(0, 1): {(0, 1): 0.7999999999999999, (1, 0): 0.2},(-1, 0): {(0, 0): 0.7, (1, 0): 0.2, (0, 1): 0.1},(0, -1): {(0, 0): 0.7, (1, 0): 0.1, (0, 1): 0.2}},(0, 1): {(1, 0): {(1, 1): 0.7999999999999999, (0, 1): 0.1, (0, 2): 0.1},(0, 1): {(0, 2): 0.7999999999999999, (0, 0): 0.2},(-1, 0): {(0, 1): 0.8999999999999999, (0, 0): 0.1},(0, -1): {(0, 0): 0.7999999999999999, (0, 2): 0.1, (0, 1): 0.1}},(0, 2): {(1, 0): {(1, 2): 0.7999999999999999, (0, 1): 0.2},(0, 1): {(0, 3): 0.7999999999999999, (0, 1): 0.1, (1, 2): 0.1},(-1, 0): {(0, 2): 0.7, (0, 1): 0.1, (1, 2): 0.1, (0, 3): 0.1},(0, -1): {(0, 1): 0.8999999999999999, (0, 3): 0.1}},(0, 3): {(1, 0): {(1, 3): 0.8999999999999999, (0, 2): 0.1},(0, 1): {(0, 4): 0.7999999999999999, (0, 3): 0.2},(-1, 0): {(0, 3): 0.8999999999999999, (0, 4): 0.1},(0, -1): {(0, 2): 0.8999999999999999, (1, 3): 0.1}},(0, 4): {(1, 0): {(1, 4): 0.7, (0, 3): 0.30000000000000004},(0, 1): {(0, 4): 0.7, (0, 3): 0.2, (1, 4): 0.1},(-1, 0): {(0, 4): 0.8999999999999999, (1, 4): 0.1},(0, -1): {(0, 3): 0.7, (1, 4): 0.2, (0, 4): 0.1}},(1, 0): {(1, 0): {(2, 0): 0.7, (1, 0): 0.2, (0, 0): 0.1},(0, 1): {(1, 1): 0.7999999999999999, (2, 0): 0.1, (1, 0): 0.1},(-1, 0): {(0, 0): 0.7, (1, 1): 0.2, (2, 0): 0.1},(0, -1): {(1, 0): 0.7, (2, 0): 0.1, (0, 0): 0.2}},(1, 1): {(1, 0): {(2, 1): 0.7999999999999999, (1, 0): 0.2},(0, 1): {(1, 2): 0.7, (0, 1): 0.30000000000000004},(-1, 0): {(0, 1): 0.7999999999999999, (2, 1): 0.2},(0, -1): {(1, 0): 0.7999999999999999, (2, 1): 0.1, (1, 2): 0.1}},(1, 2): {(1, 0): {(2, 2): 0.7, (1, 3): 0.2, (1, 1): 0.1},(0, 1): {(1, 3): 0.7999999999999999, (1, 1): 0.2},(-1, 0): {(0, 2): 0.7999999999999999, (1, 3): 0.2},(0, -1): {(1, 1): 0.8999999999999999, (2, 2): 0.1}},(1, 3): {(1, 0): {(2, 3): 0.7999999999999999, (1, 4): 0.2},(0, 1): {(1, 4): 0.7999999999999999, (2, 3): 0.1, (0, 3): 0.1},(-1, 0): {(0, 3): 0.7999999999999999, (2, 3): 0.2},(0, -1): {(1, 2): 0.7999999999999999, (0, 3): 0.1, (1, 4): 0.1}},(1, 4): {(1, 0): {(2, 4): 0.8999999999999999, (1, 4): 0.1},(0, 1): {(1, 4): 0.7999999999999999, (1, 3): 0.1, (0, 4): 0.1},(-1, 0): {(0, 4): 0.8999999999999999, (1, 4): 0.1},(0, -1): {(1, 3): 0.7999999999999999, (0, 4): 0.2}},(2, 0): {(1, 0): {(3, 0): 0.7999999999999999, (2, 0): 0.2},(0, 1): {(2, 1): 0.8999999999999999, (2, 0): 0.1},(-1, 0): {(1, 0): 0.7, (2, 0): 0.2, (2, 1): 0.1},(0, -1): {(2, 0): 0.7, (1, 0): 0.1, (3, 0): 0.2}},(2, 1): {(1, 0): {(3, 1): 0.7999999999999999, (1, 1): 0.1, (2, 0): 0.1},(0, 1): {(2, 2): 0.7, (3, 1): 0.2, (1, 1): 0.1},(-1, 0): {(1, 1): 0.7999999999999999, (3, 1): 0.2},(0, -1): {(2, 0): 0.7999999999999999, (3, 1): 0.2}},(2, 2): {(1, 0): {(3, 2): 0.7999999999999999, (2, 1): 0.1, (1, 2): 0.1},(0, 1): {(2, 3): 0.8999999999999999, (1, 2): 0.1},(-1, 0): {(1, 2): 0.7, (3, 2): 0.1, (2, 3): 0.1, (2, 1): 0.1},(0, -1): {(2, 1): 0.7999999999999999, (1, 2): 0.2}},(2, 3): {(1, 0): {(3, 3): 0.7999999999999999, (2, 4): 0.2},(0, 1): {(2, 4): 0.7999999999999999, (2, 2): 0.2},(-1, 0): {(1, 3): 0.7999999999999999, (2, 4): 0.1, (2, 2): 0.1},(0, -1): {(2, 2): 0.7999999999999999, (2, 4): 0.2}},(2, 4): {(1, 0): {(3, 4): 0.7, (2, 3): 0.2, (1, 4): 0.1},(0, 1): {(2, 4): 0.7999999999999999, (3, 4): 0.1, (2, 3): 0.1},(-1, 0): {(1, 4): 0.7999999999999999, (3, 4): 0.2},(0, -1): {(2, 3): 0.7999999999999999, (3, 4): 0.1, (1, 4): 0.1}},(3, 0): {(1, 0): {(4, 0): 0.7, (3, 0): 0.2, (2, 0): 0.1},(0, 1): {(3, 1): 0.7999999999999999, (4, 0): 0.2},(-1, 0): {(2, 0): 0.8999999999999999, (3, 0): 0.1},(0, -1): {(3, 0): 0.9999999999999999}},(3, 1): {(1, 0): {(4, 1): 0.7, (2, 1): 0.1, (3, 2): 0.1, (3, 0): 0.1},(0, 1): {(3, 2): 0.7999999999999999, (4, 1): 0.1, (3, 0): 0.1},(-1, 0): {(2, 1): 0.7999999999999999, (4, 1): 0.1, (3, 0): 0.1},(0, -1): {(3, 0): 0.7, (3, 2): 0.2, (4, 1): 0.1}},(3, 2): {(1, 0): {(4, 2): 0.7, (3, 1): 0.2, (3, 3): 0.1},(0, 1): {(3, 3): 0.7, (4, 2): 0.30000000000000004},(-1, 0): {(2, 2): 0.7, (3, 3): 0.2, (3, 1): 0.1},(0, -1): {(3, 1): 0.7, (3, 3): 0.1, (4, 2): 0.2}},(3, 3): {(1, 0): {(4, 3): 0.8999999999999999, (3, 2): 0.1},(0, 1): {(3, 4): 0.9999999999999999},(-1, 0): {(2, 3): 0.7999999999999999, (3, 4): 0.1, (3, 2): 0.1},(0, -1): {(3, 2): 0.7, (3, 4): 0.1, (4, 3): 0.2}},(3, 4): {(1, 0): {(4, 4): 0.8999999999999999, (2, 4): 0.1},(0, 1): {(3, 4): 0.7, (3, 3): 0.1, (2, 4): 0.1, (4, 4): 0.1},(-1, 0): {(2, 4): 0.7, (3, 4): 0.2, (4, 4): 0.1},(0, -1): {(3, 3): 0.7999999999999999, (2, 4): 0.1, (3, 4): 0.1}},(4, 0): {(1, 0): {(4, 0): 0.7999999999999999, (4, 1): 0.1, (3, 0): 0.1},(0, 1): {(4, 1): 0.8999999999999999, (4, 0): 0.1},(-1, 0): {(3, 0): 0.7, (4, 0): 0.2, (4, 1): 0.1},(0, -1): {(4, 0): 0.7, (4, 1): 0.30000000000000004}},(4, 1): {(1, 0): {(4, 1): 0.7, (4, 2): 0.1, (3, 1): 0.1, (4, 0): 0.1},(0, 1): {(4, 2): 0.7, (4, 0): 0.2, (3, 1): 0.1},(-1, 0): {(3, 1): 0.7999999999999999, (4, 0): 0.2},(0, -1): {(4, 0): 0.7999999999999999, (4, 2): 0.1, (4, 1): 0.1}},(4, 2): {(1, 0): {(4, 2): 0.8999999999999999, (4, 3): 0.1},(0, 1): {(4, 3): 0.7, (4, 1): 0.1, (4, 2): 0.2},(-1, 0): {(3, 2): 0.7999999999999999, (4, 1): 0.1, (4, 3): 0.1},(0, -1): {(4, 1): 0.7999999999999999, (4, 3): 0.1, (4, 2): 0.1}},(4, 3): {(1, 0): {(4, 3): 0.8999999999999999, (4, 4): 0.1},(0, 1): {(4, 4): 0.7999999999999999, (4, 3): 0.2},(-1, 0): {(3, 3): 0.7, (4, 2): 0.2, (4, 4): 0.1},(0, -1): {(4, 2): 0.7999999999999999, (3, 3): 0.2}},(4, 4): {(1, 0): {(4, 4): 0.8999999999999999, (4, 3): 0.1},(0, 1): {(4, 4): 0.7999999999999999, (3, 4): 0.2},(-1, 0): {(3, 4): 0.7999999999999999, (4, 3): 0.2},(0, -1): {(4, 3): 0.7999999999999999, (4, 4): 0.1, (3, 4): 0.1}}}
    reward = {(0, 0): {(1, 0): {(1, 0): -1, (0, 1): -1, (0, 0): -1},(0, 1): {(0, 1): -1, (1, 0): -1},(-1, 0): {(0, 0): -1, (1, 0): -1, (0, 1): -1},(0, -1): {(0, 0): -1, (1, 0): -1, (0, 1): -1}},(0, 1): {(1, 0): {(1, 1): -1, (0, 1): -1, (0, 2): -1},(0, 1): {(0, 2): -1, (0, 0): -1},(-1, 0): {(0, 1): -1, (0, 0): -1},(0, -1): {(0, 0): -1, (0, 2): -1, (0, 1): -1}},(0, 2): {(1, 0): {(1, 2): -1, (0, 1): -1},(0, 1): {(0, 3): -1, (0, 1): -1, (1, 2): -1},(-1, 0): {(0, 2): -1, (0, 1): -1, (1, 2): -1, (0, 3): -1},(0, -1): {(0, 1): -1, (0, 3): -1}},(0, 3): {(1, 0): {(1, 3): -1, (0, 2): -1},(0, 1): {(0, 4): -1, (0, 3): -1},(-1, 0): {(0, 3): -1, (0, 4): -1},(0, -1): {(0, 2): -1, (1, 3): -1}},(0, 4): {(1, 0): {(1, 4): -1, (0, 3): -1},(0, 1): {(0, 4): -1, (0, 3): -1, (1, 4): -1},(-1, 0): {(0, 4): -1, (1, 4): -1},(0, -1): {(0, 3): -1, (1, 4): -1, (0, 4): -1}},(1, 0): {(1, 0): {(2, 0): -1, (1, 0): -1, (0, 0): -1},(0, 1): {(1, 1): -1, (2, 0): -1, (1, 0): -1},(-1, 0): {(0, 0): -1, (1, 1): -1, (2, 0): -1},(0, -1): {(1, 0): -1, (2, 0): -1, (0, 0): -1}},(1, 1): {(1, 0): {(2, 1): -100, (1, 0): -100},(0, 1): {(1, 2): -100, (0, 1): -100},(-1, 0): {(0, 1): -100, (2, 1): -100},(0, -1): {(1, 0): -100, (2, 1): -100, (1, 2): -100}},(1, 2): {(1, 0): {(2, 2): -1, (1, 3): -1, (1, 1): -1},(0, 1): {(1, 3): -1, (1, 1): -1},(-1, 0): {(0, 2): -1, (1, 3): -1},(0, -1): {(1, 1): -1, (2, 2): -1}},(1, 3): {(1, 0): {(2, 3): -1, (1, 4): -1},(0, 1): {(1, 4): -1, (2, 3): -1, (0, 3): -1},(-1, 0): {(0, 3): -1, (2, 3): -1},(0, -1): {(1, 2): -1, (0, 3): -1, (1, 4): -1}},(1, 4): {(1, 0): {(2, 4): -1, (1, 4): -1},(0, 1): {(1, 4): -1, (1, 3): -1, (0, 4): -1},(-1, 0): {(0, 4): -1, (1, 4): -1},(0, -1): {(1, 3): -1, (0, 4): -1}},(2, 0): {(1, 0): {(3, 0): -1, (2, 0): -1},(0, 1): {(2, 1): -1, (2, 0): -1},(-1, 0): {(1, 0): -1, (2, 0): -1, (2, 1): -1},(0, -1): {(2, 0): -1, (1, 0): -1, (3, 0): -1}},(2, 1): {(1, 0): {(3, 1): -1, (1, 1): -1, (2, 0): -1},(0, 1): {(2, 2): -1, (3, 1): -1, (1, 1): -1},(-1, 0): {(1, 1): -1, (3, 1): -1},(0, -1): {(2, 0): -1, (3, 1): -1}},(2, 2): {(1, 0): {(3, 2): -1, (2, 1): -1, (1, 2): -1},(0, 1): {(2, 3): -1, (1, 2): -1},(-1, 0): {(1, 2): -1, (3, 2): -1, (2, 3): -1, (2, 1): -1},(0, -1): {(2, 1): -1, (1, 2): -1}},(2, 3): {(1, 0): {(3, 3): -1, (2, 4): -1},(0, 1): {(2, 4): -1, (2, 2): -1},(-1, 0): {(1, 3): -1, (2, 4): -1, (2, 2): -1},(0, -1): {(2, 2): -1, (2, 4): -1}},(2, 4): {(1, 0): {(3, 4): -1, (2, 3): -1, (1, 4): -1},(0, 1): {(2, 4): -1, (3, 4): -1, (2, 3): -1},(-1, 0): {(1, 4): -1, (3, 4): -1},(0, -1): {(2, 3): -1, (3, 4): -1, (1, 4): -1}},(3, 0): {(1, 0): {(4, 0): -1, (3, 0): -1, (2, 0): -1},(0, 1): {(3, 1): -1, (4, 0): -1},(-1, 0): {(2, 0): -1, (3, 0): -1},(0, -1): {(3, 0): -1}},(3, 1): {(1, 0): {(4, 1): 10, (2, 1): 10, (3, 2): 10, (3, 0): 10},(0, 1): {(3, 2): 10, (4, 1): 10, (3, 0): 10},(-1, 0): {(2, 1): 10, (4, 1): 10, (3, 0): 10},(0, -1): {(3, 0): 10, (3, 2): 10, (4, 1): 10}},(3, 2): {(1, 0): {(4, 2): -1, (3, 1): -1, (3, 3): -1},(0, 1): {(3, 3): -1, (4, 2): -1},(-1, 0): {(2, 2): -1, (3, 3): -1, (3, 1): -1},(0, -1): {(3, 1): -1, (3, 3): -1, (4, 2): -1}},(3, 3): {(1, 0): {(4, 3): -1, (3, 2): -1},(0, 1): {(3, 4): -1},(-1, 0): {(2, 3): -1, (3, 4): -1, (3, 2): -1},(0, -1): {(3, 2): -1, (3, 4): -1, (4, 3): -1}},(3, 4): {(1, 0): {(4, 4): -1, (2, 4): -1},(0, 1): {(3, 4): -1, (3, 3): -1, (2, 4): -1, (4, 4): -1},(-1, 0): {(2, 4): -1, (3, 4): -1, (4, 4): -1},(0, -1): {(3, 3): -1, (2, 4): -1, (3, 4): -1}},(4, 0): {(1, 0): {(4, 0): -1, (4, 1): -1, (3, 0): -1},(0, 1): {(4, 1): -1, (4, 0): -1},(-1, 0): {(3, 0): -1, (4, 0): -1, (4, 1): -1},(0, -1): {(4, 0): -1, (4, 1): -1}},(4, 1): {(1, 0): {(4, 1): -1, (4, 2): -1, (3, 1): -1, (4, 0): -1},(0, 1): {(4, 2): -1, (4, 0): -1, (3, 1): -1},(-1, 0): {(3, 1): -1, (4, 0): -1},(0, -1): {(4, 0): -1, (4, 2): -1, (4, 1): -1}},(4, 2): {(1, 0): {(4, 2): -1, (4, 3): -1},(0, 1): {(4, 3): -1, (4, 1): -1, (4, 2): -1},(-1, 0): {(3, 2): -1, (4, 1): -1, (4, 3): -1},(0, -1): {(4, 1): -1, (4, 3): -1, (4, 2): -1}},(4, 3): {(1, 0): {(4, 3): -1, (4, 4): -1},(0, 1): {(4, 4): -1, (4, 3): -1},(-1, 0): {(3, 3): -1, (4, 2): -1, (4, 4): -1},(0, -1): {(4, 2): -1, (3, 3): -1}},(4, 4): {(1, 0): {(4, 4): -1, (4, 3): -1},(0, 1): {(4, 4): -1, (3, 4): -1},(-1, 0): {(3, 4): -1, (4, 3): -1},(0, -1): {(4, 3): -1, (4, 4): -1, (3, 4): -1}}}
    value = {state:0 for state in reward.keys()}
    performValueIteration = ValueIteration(transition, reward, value, convergence, gamma)
    optimalValuesTest, policyTest = performValueIteration()
    #print(optimalValuesTest)
    #print(policyTest)

if __name__ == '__main__':
    main()